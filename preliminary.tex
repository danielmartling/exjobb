\clearpage{\thispagestyle{empty}}
\section{Preliminary topics}

\subsection{Group theoretical topics}

\subsubsection{Group action}

We could let the group $G$ act on a set $X$ and study the action of $G$ on $X$ defined by
\begin{align*}
	G \times X \rightarrow X
\end{align*}
and thereby permuting the elements of $X$ by for any $g \in G$,
\begin{align*}
	(g,x) \mapsto g \cdot x = gx,
\end{align*}
for any $x \in X$.

\subsubsection{The symmetric group}

Denote by $\Sym_n$ the set of bijections of $\{1, 2, \dots n\}$, which is a group under composition of bijections. The number of elements in $\Sym_n$ is $n!$.

\begin{example}
	The elements of $\Sym_3$ are
	\begin{align*}
		(1), (1,2), (1,3), (2,3), (123), (132).
	\end{align*}
	There are $3! = 6$ elements: the identity element (denoted $e$), three transpositions and two 3-cycles.
\end{example}

\begin{definition}[Sign of a permutation]
	Let $\sigma \in \Sym_n$, then the sign of $\sigma$ is defined as a function
	\begin{align*}
		\sgn: & \ \Sym_n \rightarrow \{+1, -1\},\\
		\sgn: & \ \sigma \mapsto (-1)^k
	\end{align*}
	where $k$ is the number of transpositions required to compose $\sigma$. If $k$ is an even integer, then $\sigma$ is called even, and vice versa for an odd $k$.
\end{definition}

Note that if $\sigma$ is composed of $s$ transpositions and $\tau$ is composed of $t$ transposition, then their composition $\sigma\tau$ is composed of $s+t$ transpositions, in some representation of $\sigma\tau$. Is the sign function still well-defined? That is, can a permutation be expressed both as a composition of even number and of a odd number of transpositions?

\begin{proposition}\label{prop:signwelldefined}
	The sign of a permutation is well-defined. That is a permutation is either \textit{even} with sign +1 or \textit{odd} with sign -1.
\end{proposition}
\begin{proof}
	\cite[Thm.12.6.1.]{Biggs}
\end{proof}

Recall that two elements $\sigma, \tau \in \Sym_n$ are conjugate if there exists a $\pi \in \Sym_n$ such that $\sigma = \pi \tau \pi^{-1}$. The conjugacy classes partition $\Sym_n$ into disjoint subsets. 

\begin{proposition}[Conjugacy in $\Sym_n$]\marginnote{SOURCE+PROOF}
	Any elements $\sigma, \tau \in \Sym_n$ are conjugate if and only if they are of the same cycle type.
\end{proposition}





\subsection{Linear algebra topics}

	\subsubsection{Trace}
		
		The trace of a matrix is defined as the sum along the diagonal, ie. for a $n \times n$ matrix $X = (x_{ij})$ we have
		\begin{align*}
			\Tr X = \sum_{i=1}^{n} x_{ii}.
		\end{align*}
		
		Recall that if two matrices $X$ and $Y$ are conjugate there exists a matrix $T$ such that $XT = TY$, or if $T$ is invertible $X = TYT^{-1}$. If $X$ and $Y$ are conjugate, then they have the same trace??????? EIGENVALUES??????

	\subsubsection{Definition of kernel and image of a map}
	
	\begin{definition}[Kernel and image of a linear map]\label{def:kernelimage}
		Let $V$ and $W$ be two vector spaces and let $\varphi: V \rightarrow W$ be a linear map. Then the kernel and the image of the map are defined thusly:
		\begin{itemize}
			\item[i)] $\ker \varphi = \left\lbrace \vvec \in V \ \middle\vert \ \varphi(\vvec) = \0 \right\rbrace = \varphi^{-1}(\0)$.
			\item[ii)] $\im \varphi = \left\lbrace \wvec \in W \ \middle\vert \ \exists \vvec \in V \text{ s.t. } \varphi(\vvec) = \wvec \right\rbrace = \varphi(V)$.
		\end{itemize}
	\end{definition}
	
	\begin{remark}
		The kernel and the image of a linear map are subspaces of the domain and codomain of the map respectively, ie. $\ker \varphi$ is a subspace of $V$ and $\im \varphi$ is a subspace of $W$.
	\end{remark}
	
	\subsubsection{Existence of complementary subspaces}
	
	\begin{corollary}\label{thm:compsubspaces}
		Let $V$ be a vector space and $W$ be a vector subspace of $V$. Then there exists a complementary vector subspace $W'$ in $V$ such that $W \cap W' = \emptyset$ and $W \cup W' = V$. This is equivalent to saying that $V$ is the direct sum of $W$ and $W'$, denoted as $V = W \oplus W'$.
	\end{corollary}
	\begin{proof}
		La la la
	\end{proof}
	
	\subsubsection{Tensor algebra}\label{sect:tensoralgebra}
	
		\begin{definition}[Bilinearity]
			content...
		\end{definition}
	
		Let $V$ and $W$ be vector spaces provided with respective bases $(\vhat_i)_{i=1}^m$ and $(\uhat_i)_{i=1}^n$, where $m = \dim V$ and $n = \dim W$. Let $\vvec \in V$ and $\wvec \in W$. Also, let $f: \GL(V)$ and $g: \GL(W)$ be linear maps. In the bases provided let the matrices of $f$ and $g$ be $F=(f_{ij})_{m \times m} \in \GL_m(\CC)$ and $G = (g_{ij})_{n \times n} \in \GL_n(\CC)$ with eigen values $\{\lambda_i\}$ and $\{\mu_i\}$, then the following vector spaces may be constructed, or rather extended bilinearly, from $V$ and $W$:
		
		\begin{itemize}
			\item The \emph{direct sum of $V$ and $W$}, denoted $V \oplus W$.
				\subitem It has the basis $(\vhat_i \oplus \what_j)_{1 \leq i \leq m}^{1 \leq j \leq n}$, and is of dimension $m+n$.
%				\subitem It has the basis $(\vhat_i \oplus \what_j)_{i = i,}^{m} _{j=1}^n$, and is of dimension $m+n$.
				\subitem An element of $V \oplus W$ looks like \begin{align*}
					\vvec \oplus \wvec = \begin{pmatrix}
						\vvec \\ \wvec
					\end{pmatrix} = \begin{pmatrix}
					v_1, v_2, \dots, v_m, w_1, w_2, \dots, w_n
					\end{pmatrix}^T.
				\end{align*}
				\subitem In the basis provided, $F \oplus G \in \GL(V \oplus W)$ is the $m+n \times m+n$ block matrix 
				\begin{align*}
					\begin{pmatrix}
						F & \0 \\ 
						\0 & G
					\end{pmatrix},
				\end{align*}
				and its action on $\vvec \oplus \wvec$ is 
				\begin{align*}
					(F \oplus G ) \cdot (\vvec  \oplus \wvec) &= \begin{pmatrix}
						F & \0 \\ 
						\0 & G
					\end{pmatrix} \cdot \begin{pmatrix}
					\vvec \\ \wvec
					\end{pmatrix} \\ 
					&= \begin{pmatrix}
					F\vvec \\ G\wvec
					\end{pmatrix}  \\ 
					&= F\vvec \oplus G\wvec.
				\end{align*}
				\subitem The trace of $F \oplus G$ is clearly the sum of the traces of $F$ and $G$, hence the eigen values of $f$ and $g$ are also eigen values of $f \oplus g$, that is the eigen values are $\{\lambda_i\} \cup \{\mu_j\}$.
				
			\item By recursion, the \emph{direct sum of $n$ copies of $V$}, denoted $nV$.
				\subitem \begin{example}
					The direct sum of $n$ copies of a field $\KK$, is usually denoted $\KK^n$, eg. $\RR^3$.
				\end{example}
				
			\item The \emph{tensor product of $V$ and $W$}, denoted $V \otimes W$.
				\subitem It has the basis $(\vhat_i \otimes \what_j)_{1 \leq i \leq m}^{1 \leq j \leq n}$, and is of dimension $mn$.
				\subitem An element of $V \otimes W$ looks like \begin{align*}
					\vvec \otimes \wvec = \begin{pmatrix}
						v_1\wvec, v_2\wvec, \dots, v_m\wvec
					\end{pmatrix}^T = \begin{pmatrix}
						v_i\wvec
					\end{pmatrix}_{mn \times 1} 
				\end{align*}
				\subitem In the basis provided, $F \otimes G \in \GL(V \otimes W)$ is the block matrix 
				\begin{align*}
					(f_{ij}G)_{mn \times mn}
				\end{align*}
				and its action on $\vvec \oplus \wvec$ is 
				\begin{align*}
					(F \otimes G ) \cdot (\vvec  \otimes \wvec) &= \begin{pmatrix}
						f_{ij}G
					\end{pmatrix}\cdot \begin{pmatrix}
						v_i\wvec
					\end{pmatrix} \\ 
					&= \begin{pmatrix}
						f_{ij}G v_i \wvec
					\end{pmatrix} \\ 
					&= \begin{pmatrix}
						f_{ij} v_i G\wvec
					\end{pmatrix} \\
					&=  \begin{pmatrix}
						f_{ij}v_i
					\end{pmatrix} \otimes G\wvec \\
					&= F\vvec \otimes G\wvec.
				\end{align*}
				\subitem The trace of $F \otimes G$ is the sum of the traces of the diagonal matrices in the block matrix $(f_{ij}G)$, which is 
				\begin{align*}
					f_{11} \Tr G + f_{22} \Tr G + \dots + f_{mm} \Tr G = \Tr F \cdot \Tr G
				\end{align*}
				hence the eigen values of $f \otimes g$ are $\{\lambda_i \cdot \mu_j\}$.
				
			\item By recursion, the \emph{$n$th tensor power of $V$}, denoted $V^{\otimes n}$. By definition, the first tensor power is the space itself, and the zeroth power is the ground field.
			
			\item The $n$th tensor power of $V$ has two subspaces, the symmetric powers $\SymP^n V$ and the alternating powers $\AltP^n V$. EEEEEH further definition?? In particular the symmetric and exterior squares are such that
			\begin{align*}
				V \otimes V = \SymP^2 V \oplus \AltP^2 V.
			\end{align*}\marginnote{need more text/proof}
			
			\item After fixing the basis $(\bas_i)_{i=1}^m$ for $V$, the dual space $V^*$ can be constructed by the duals $\bas_i^*$ defined by... It is identified with the set of all linear functions from $V$ to $\CC$.\marginnote{need more text/proof}
			
			\item Set of homomoprhisms $V$ to $W$.\marginnote{need more text/proof}
			
		\end{itemize} 
		
	

		
		
		